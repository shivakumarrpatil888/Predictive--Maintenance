{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzOmRSoxRqkR",
        "outputId": "23121f6c-f35f-4163-a770-6e0a82e0f01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-60bfc5db3e01>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['RUL'] = df.apply(lambda row: max_cycle[row['unit']] - row['time'], axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9615488762523694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:44:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.9596533983211482\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9224 - loss: 0.2270 - val_accuracy: 0.9553 - val_loss: 0.1067\n",
            "Epoch 2/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9555 - loss: 0.1065 - val_accuracy: 0.9561 - val_loss: 0.1034\n",
            "Epoch 3/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9580 - loss: 0.1062 - val_accuracy: 0.9586 - val_loss: 0.0999\n",
            "Epoch 4/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9565 - loss: 0.1036 - val_accuracy: 0.9602 - val_loss: 0.0976\n",
            "Epoch 5/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9616 - loss: 0.0924 - val_accuracy: 0.9618 - val_loss: 0.0933\n",
            "Epoch 6/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9621 - loss: 0.0958 - val_accuracy: 0.9629 - val_loss: 0.0941\n",
            "Epoch 7/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9627 - loss: 0.0918 - val_accuracy: 0.9629 - val_loss: 0.0908\n",
            "Epoch 8/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9635 - loss: 0.0884 - val_accuracy: 0.9615 - val_loss: 0.0875\n",
            "Epoch 9/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9648 - loss: 0.0885 - val_accuracy: 0.9634 - val_loss: 0.0834\n",
            "Epoch 10/10\n",
            "\u001b[1m462/462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9626 - loss: 0.0873 - val_accuracy: 0.9632 - val_loss: 0.0881\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Accuracy: 0.9631735716219876\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Load dataset\n",
        "data_path =\"/content/train_FD001.txt\"  # Adjust path accordingly\n",
        "df = pd.read_csv(data_path, sep=\" \", header=None, engine='python')\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "def preprocess_data(df):\n",
        "    df = df.dropna(axis=1, how='all')  # Drop empty columns\n",
        "    columns = ['unit', 'time', 'operational_setting_1', 'operational_setting_2',\n",
        "               'operational_setting_3', 'sensor_1', 'sensor_2', 'sensor_3',\n",
        "               'sensor_4', 'sensor_5', 'sensor_6', 'sensor_7', 'sensor_8',\n",
        "               'sensor_9', 'sensor_10', 'sensor_11', 'sensor_12', 'sensor_13',\n",
        "               'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17', 'sensor_18',\n",
        "               'sensor_19', 'sensor_20', 'sensor_21']\n",
        "    df.columns = columns\n",
        "\n",
        "    # Compute Remaining Useful Life (RUL)\n",
        "    max_cycle = df.groupby('unit')['time'].max()\n",
        "    df['RUL'] = df.apply(lambda row: max_cycle[row['unit']] - row['time'], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = preprocess_data(df)\n",
        "\n",
        "# Feature selection\n",
        "features = ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_7', 'sensor_8', 'sensor_11', 'sensor_13', 'sensor_15']\n",
        "X = df[features]\n",
        "y = (df['RUL'] <= 20).astype(int)  # Binary classification: Failure within 20 cycles\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "\n",
        "# Train LSTM model\n",
        "X_train_lstm = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_lstm = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, validation_data=(X_test_lstm, y_test))\n",
        "\n",
        "# Evaluate LSTM model\n",
        "y_pred_lstm = (model.predict(X_test_lstm) > 0.5).astype(int)\n",
        "print(\"LSTM Accuracy:\", accuracy_score(y_test, y_pred_lstm))\n",
        "\n",
        "# Save trained models\n",
        "import joblib\n",
        "\n",
        "joblib.dump(rf, 'random_forest_model.pkl')\n",
        "joblib.dump(xgb, 'xgboost_model.pkl')\n",
        "model.save('lstm_model.h5')"
      ]
    }
  ]
}